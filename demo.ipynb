{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HeligateTeam/VQA.git\n"
      ],
      "metadata": {
        "id": "Z-fI32pAJQ1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code line MUST run everytime you run the notebook\n",
        "%cd VQA"
      ],
      "metadata": {
        "id": "YdjBiwZ9JXt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HynlazMAJGw7"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uArdu2nLJGw-"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output, Image, display\n",
        "import PIL.Image\n",
        "import io\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from processing_image import Preprocess\n",
        "from visualizing_image import SingleImageViz\n",
        "from modeling_frcnn import GeneralizedRCNN\n",
        "from utils import Config\n",
        "import utils\n",
        "from transformers import LxmertForQuestionAnswering, LxmertTokenizer\n",
        "import wget\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "OBJ_URL = \"https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/genome/1600-400-20/objects_vocab.txt\"\n",
        "ATTR_URL = \"https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/genome/1600-400-20/attributes_vocab.txt\"\n",
        "VQA_URL = \"https://raw.githubusercontent.com/airsplay/lxmert/master/data/vqa/trainval_label2ans.json\"\n",
        "\n",
        "\n",
        "# for visualizing output\n",
        "def showarray(a, fmt=\"jpeg\"):\n",
        "    a = np.uint8(np.clip(a, 0, 255))\n",
        "    f = io.BytesIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    display(Image(data=f.getvalue()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_5uD2XFJGxA"
      },
      "outputs": [],
      "source": [
        "# load object, attribute, and answer labels\n",
        "\n",
        "objids = utils.get_data(OBJ_URL)\n",
        "attrids = utils.get_data(ATTR_URL)\n",
        "vqa_answers = utils.get_data(VQA_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q70xKIBQJGxA"
      },
      "outputs": [],
      "source": [
        "# load models and model components\n",
        "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
        "\n",
        "frcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=frcnn_cfg)\n",
        "\n",
        "image_preprocess = Preprocess(frcnn_cfg)\n",
        "\n",
        "lxmert_tokenizer = LxmertTokenizer.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
        "# lxmert_gqa = LxmertForQuestionAnswering.from_pretrained(\"unc-nlp/lxmert-gqa-uncased\")\n",
        "lxmert_vqa = LxmertForQuestionAnswering.from_pretrained(\"unc-nlp/lxmert-vqa-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOCYqVibJGxB"
      },
      "outputs": [],
      "source": [
        "URL = \"http://farm8.staticflickr.com/7161/6732750757_48d9cca97e_z.jpg\"\n",
        "# image viz\n",
        "frcnn_visualizer = SingleImageViz(URL, id2obj=objids, id2attr=attrids)\n",
        "# run frcnn\n",
        "images, sizes, scales_yx = image_preprocess(URL)\n",
        "output_dict = frcnn(\n",
        "    images,\n",
        "    sizes,\n",
        "    scales_yx=scales_yx,\n",
        "    padding=\"max_detections\",\n",
        "    max_detections=frcnn_cfg.max_detections,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "# add boxes and labels to the image\n",
        "\n",
        "frcnn_visualizer.draw_boxes(\n",
        "    output_dict.get(\"boxes\"),\n",
        "    output_dict.pop(\"obj_ids\"),\n",
        "    output_dict.pop(\"obj_probs\"),\n",
        "    output_dict.pop(\"attr_ids\"),\n",
        "    output_dict.pop(\"attr_probs\"),\n",
        ")\n",
        "showarray(frcnn_visualizer._get_buffer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-zMRMW7JGxB"
      },
      "outputs": [],
      "source": [
        "test_questions_for_url1 = [\n",
        "    \"Where is this scene?\",\n",
        "    \"how many people in this scene?\",\n",
        "    \"where is the umbrella?\",\n",
        "    \"what are they doing\",\n",
        "    \"how about the weather?\",\n",
        "    \"what color of the cloud?\",\n",
        "    \"what color of the gound?\",\n",
        "    \"what are the dogs doing?\"\n",
        "]\n",
        "\n",
        "# Very important that the boxes are normalized\n",
        "normalized_boxes = output_dict.get(\"normalized_boxes\")\n",
        "features = output_dict.get(\"roi_features\")\n",
        "\n",
        "for test_question in test_questions_for_url1:\n",
        "    # run lxmert\n",
        "    test_question = [test_question]\n",
        "\n",
        "    inputs = lxmert_tokenizer(\n",
        "        test_question,\n",
        "        padding=\"max_length\",\n",
        "        max_length=20,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    # run lxmert(s)\n",
        "    output_vqa = lxmert_vqa(\n",
        "        input_ids=inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        visual_feats=features,\n",
        "        visual_pos=normalized_boxes,\n",
        "        token_type_ids=inputs.token_type_ids,\n",
        "        output_attentions=False,\n",
        "    )\n",
        "    # get prediction\n",
        "    pred_vqa = output_vqa[\"question_answering_score\"].argmax(-1)\n",
        "    print(\"Question:\", test_question)\n",
        "    print(\"prediction from LXMERT VQA:\", vqa_answers[pred_vqa])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hII403n1JGxC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzEshcDcJGxC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Copy of demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}